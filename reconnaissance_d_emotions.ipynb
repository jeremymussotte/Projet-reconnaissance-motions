{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDD4MHaY3_GK"
      },
      "source": [
        "# Projet reconnaissance d'émotion dans un texte"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "L'objectif de ce projet est d'aboutir à un modèle capable de reconnaître une émotion dans un court texte, en utilisant la base de données IEMOCAP.\n",
        "\n",
        "Dans un premier temps, on entraîne un réseau de neurone basé sur un article scientifique, puis on exploite des modèles de transformers pré-entraînés."
      ],
      "metadata": {
        "id": "dTH-5WwNGF4b"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7sSFP5fU3_GL"
      },
      "source": [
        "# Importations des librairies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ukcKCsGH3_GM"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from sklearn.model_selection import train_test_split\n",
        "from matplotlib import pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from transformers import BertModel, BertTokenizer, BertForSequenceClassification, RobertaForSequenceClassification, RobertaTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S5pqO_BG3_GN"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmkREKfp3_GN"
      },
      "source": [
        "# Manipulation des données\n",
        "\n",
        "Ici on extrait une liste contenant le titre de chaque extrait ainsi que l'émotion associée"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UGp2P8Vp3_GN"
      },
      "outputs": [],
      "source": [
        "# Fonction permettant de lire le fichier texte et de le transformer en tableau\n",
        "def txt_to_table(file_path, delimiter='\\t'):\n",
        "    table = []\n",
        "    with open(file_path, 'r') as file:\n",
        "        for line in file:\n",
        "            # Supprime les espaces blancs de début et de fin et divise la ligne en fonction du délimiteur.\n",
        "            fields = line.strip().split(delimiter)\n",
        "            table.append(fields)\n",
        "    return table\n",
        "\n",
        "def extract_emotions(table):\n",
        "    tableReduce = []\n",
        "    extractedList =[]\n",
        "    lenMax = len(table)\n",
        "    i= 2\n",
        "    while i<lenMax:\n",
        "      tableReduce.append(table[i])\n",
        "      i = i+1\n",
        "    for i in range (len(tableReduce)):\n",
        "      if tableReduce[i] != [\"\"]:\n",
        "       if tableReduce[i][1].startswith(\"Ses\") and tableReduce[i][2] in [\"neu\", \"ang\", \"sad\",\"fru\",\"hap\",\"exc\"]:\n",
        "                extractedList.append((tableReduce[i][1], tableReduce[i][2]))\n",
        "    return extractedList\n",
        "\n",
        "# Fonction permettant de lire le fichier texte avec un délimiteur d'espace et de le transformer en tableau\n",
        "def extract_text(file_path):\n",
        "    table = []\n",
        "    transformedTable = []\n",
        "    with open(file_path, 'r') as file:\n",
        "        for line in file:\n",
        "            # Diviser la ligne en fonction du délimiteur d'espace\n",
        "            fields = line.strip().split()\n",
        "            table.append(fields)\n",
        "    for row in table :\n",
        "      transformedRow = [row[0], ' '.join(row[2:])]\n",
        "      transformedTable.append(transformedRow)\n",
        "    return transformedTable\n",
        "\n",
        "def sentence_label(extractedList,extractedText):\n",
        "  labeledText = []\n",
        "  for i in range (len(extractedList)):\n",
        "    j = 0\n",
        "    while((extractedText[j][0] != extractedList[i][0]) and (j < len(extractedList))):\n",
        "      j = j+1\n",
        "    labeledText.append((extractedText[j][1],extractedList[i][1]))\n",
        "  return labeledText"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l5EwN_Yn3_GO"
      },
      "outputs": [],
      "source": [
        "# Si cloné\n",
        "# Traitement général de toutes les données\n",
        "chemin_emo_part = r\"EmoEvaluation/EmoEvaluation\"\n",
        "chemin_transcription_part = r\"transcriptions/transcriptions\"\n",
        "\n",
        "data = []\n",
        "session_folders = ['Session_01', 'Session_02', 'Session_03', 'Session_04', 'Session_05']\n",
        "for session in session_folders:\n",
        "  emotions_folder = os.path.join('/IEMOCAP', session,chemin_emo_part)\n",
        "  listFileEmotions = os.listdir(emotions_folder)\n",
        "  text_folder = os.path.join('/IEMOCAP', session, chemin_transcription_part)\n",
        "  listFileText = os.listdir(text_folder)\n",
        "  for i in range(len(listFileEmotions)):\n",
        "    filePathEmotions = os.path.join(emotions_folder,listFileEmotions[i])\n",
        "    if os.path.isfile(filePathEmotions):\n",
        "      filePathText = os.path.join(text_folder,listFileText[i])\n",
        "      tableEmotions = txt_to_table(filePathEmotions)\n",
        "      extractedEmotions = extract_emotions(tableEmotions)\n",
        "      extractedText = extract_text(filePathText)\n",
        "      labeledText = sentence_label(extractedEmotions,extractedText)\n",
        "      data.extend(labeledText)\n",
        "\n",
        "print(data)\n",
        "print(len(data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OlVo0LSB3_GO",
        "outputId": "f4134f91-1175-4fd4-fcf9-365476026854"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7380\n"
          ]
        }
      ],
      "source": [
        "# si en local\n",
        "# Traitement général de toutes les données\n",
        "\n",
        "chemin_data = r\"C:\\Users\\Fournier\\Documents\\Cours CS\\ST7 numérique au service du facteur humain\\IA reconnaissance émotion\\IEMOCAP\"\n",
        "chemin_emo_part = r\"EmoEvaluation\\EmoEvaluation\"\n",
        "chemin_transcription_part = r\"transcriptions\\transcriptions\"\n",
        "\n",
        "data = []\n",
        "session_folders = ['Session_01', 'Session_02', 'Session_03', 'Session_04', 'Session_05']\n",
        "for session in session_folders:\n",
        "  emotions_folder = os.path.join(chemin_data, session, chemin_emo_part)\n",
        "  listFileEmotions = os.listdir(emotions_folder)\n",
        "  text_folder = os.path.join(chemin_data, session, chemin_transcription_part)\n",
        "  listFileText = os.listdir(text_folder)\n",
        "  for i in range(len(listFileEmotions)):\n",
        "    filePathEmotions = os.path.join(emotions_folder,listFileEmotions[i])\n",
        "    if os.path.isfile(filePathEmotions):\n",
        "      filePathText = os.path.join(text_folder,listFileText[i])\n",
        "      tableEmotions = txt_to_table(filePathEmotions)\n",
        "      extractedEmotions = extract_emotions(tableEmotions)\n",
        "      extractedText = extract_text(filePathText)\n",
        "      labeledText = sentence_label(extractedEmotions,extractedText)\n",
        "      data.extend(labeledText)\n",
        "print(len(data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n0fKmpDk3_GQ",
        "outputId": "4fcbd1cb-f7d3-4102-9f38-9cbe235cb615"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nombre de neutre:1708 ; nombre de angry:1103 ; nombre de happy:595 ; nombre de sad:1084 ; nombre de excited:1041 ; nombre de frustrated:1849\n"
          ]
        }
      ],
      "source": [
        "neu_data = [text for text, emotion in data if emotion == \"neu\"]\n",
        "ang_data = [text for text, emotion in data if emotion == \"ang\"]\n",
        "hap_data = [text for text, emotion in data if emotion == \"hap\"]\n",
        "sad_data = [text for text, emotion in data if emotion == \"sad\"]\n",
        "fru_data = [text for text, emotion in data if emotion == \"fru\"]\n",
        "exc_data = [text for text, emotion in data if emotion == \"exc\"]\n",
        "neu_array = np.array(neu_data)\n",
        "ang_array = np.array(ang_data)\n",
        "hap_array = np.array(hap_data)\n",
        "sad_array = np.array(sad_data)\n",
        "exc_array = np.array(exc_data)\n",
        "fru_array = np.array(fru_data)\n",
        "\n",
        "print(f\"nombre de neutre:{len(neu_array)} ; nombre de angry:{len(ang_array)} ; nombre de happy:{len(hap_array)} ; nombre de sad:{len(sad_array)} ; nombre de excited:{len(exc_array)} ; nombre de frustrated:{len(fru_array)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLIy2maZ3_GR"
      },
      "source": [
        "# Le batch des données :\n",
        "\n",
        "Dans cette partie je vais batcher les données, les reunirs en paquets afin que les futurs réseaux s'entrainent dessus correctement et efficacement. Comme vu ci dessus, les classes sont déséquilibrées, il va falloir prendre cela en compte dans notre batch de données pour éviter un oversampling sur les classes les plus représenté lors de l'entrainement.\n",
        "\n",
        "Je décide donc de faire des batchs de 60 transcriptions, avec 10 de chaque classe (neutral, angry, happy, sad, excited, frustrated)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-rUhc-c3_GR"
      },
      "outputs": [],
      "source": [
        "class_indices = {\n",
        "    0: neu_array,\n",
        "    1: ang_array,\n",
        "    2: hap_array,\n",
        "    3: sad_array,\n",
        "    4: exc_array,\n",
        "    5: fru_array\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nVxKGlqp3_GS"
      },
      "outputs": [],
      "source": [
        "# Définir le nbr d'exemple pour 1 émotion dans 1 batch\n",
        "nbr_emo_par_batch = 10\n",
        "\n",
        "# Concaténer toutes les valeurs et les labels dans des listes séparées\n",
        "X = np.concatenate(list(class_indices.values()))\n",
        "y = np.concatenate([[key] * len(class_indices[key]) for key in class_indices])\n",
        "\n",
        "# Créer un objet StratifiedShuffleSplit, cela sert pour faire une validation croisé en split pour fine-tuned un model pré-trained, on pourra donc en avoir besoin par la suite\n",
        "# sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "# ici on créé quatres listes, deux de train et deux de test de taille 80% desdonnées pour le train et 20% pour le test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, shuffle=True, random_state=42)\n",
        "\n",
        "\n",
        "compteur = [0,0,0,0,0,0]\n",
        "for i in y_train :\n",
        "    compteur[i-1] +=1\n",
        "\n",
        "print(compteur)\n",
        "\n",
        "nbr_batch_train = min(compteur[i] // nbr_emo_par_batch for i in range(len(compteur)))\n",
        "\n",
        "print(nbr_batch_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FD0FDC5K3_GS"
      },
      "outputs": [],
      "source": [
        "def creer_batch_train_random(X_train,y_train):\n",
        "    all_batches = []\n",
        "\n",
        "    all_batches_indices = []\n",
        "\n",
        "        # Créer des batches équilibrés pour chaque split\n",
        "    for i in range(nbr_batch_train):\n",
        "        # Sélectionner des indices équilibrés de chaque classe pour former un batch\n",
        "        batch_indices = []\n",
        "        for label in np.unique(y_train):\n",
        "\n",
        "            indices_du_label = []\n",
        "\n",
        "            while len(indices_du_label) != nbr_emo_par_batch:\n",
        "\n",
        "                indice_valeur = np.random.choice(np.where(np.array(y_train) == label)[0])\n",
        "\n",
        "                if indice_valeur not in indices_du_label:\n",
        "                    if indice_valeur not in all_batches_indices:\n",
        "                        indices_du_label.append(indice_valeur)\n",
        "\n",
        "\n",
        "            batch_indices.extend(indices_du_label)\n",
        "            all_batches_indices.extend(indices_du_label)\n",
        "\n",
        "        # Mélanger les indices du batch final\n",
        "        np.random.shuffle(batch_indices)\n",
        "\n",
        "            # Créer le batch en combinant X_batch et y_batch\n",
        "        batch = [(X_train[index], y_train[index]) for index in batch_indices]\n",
        "\n",
        "        # Ajouter le batch à la liste\n",
        "        all_batches.append(batch)\n",
        "\n",
        "    return all_batches\n",
        "\n",
        "all_batches = creer_batch_train_random(X_train,y_train)\n",
        "\n",
        "# Vérifier la taille de la liste de batches\n",
        "print(len(all_batches))  # Devrait afficher le nombre total de batches\n",
        "print(len(all_batches[0]))  # Devrait afficher la taille du premier batch\n",
        "print(all_batches[0])\n",
        "\n",
        "# repartition des label:\n",
        "compteur_label=[0,0,0,0,0,0]\n",
        "for donnee,label in all_batches[0]:\n",
        "    compteur_label[label] +=1\n",
        "print(compteur_label)  # Devrait afficher la répartition des émotions dans un batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UogNV08u3_GT"
      },
      "outputs": [],
      "source": [
        "def train(model, loss_fn, optimizer, n_epochs=1):\n",
        "\n",
        "    model.train(True)\n",
        "\n",
        "    loss_train = np.zeros(n_epochs)\n",
        "    acc_train = np.zeros(n_epochs)\n",
        "\n",
        "    for epoch_num in range(n_epochs):\n",
        "\n",
        "        running_corrects = 0.0 # nombre de prédiction juste\n",
        "        running_loss = 0.0 # loss\n",
        "        size = 0\n",
        "\n",
        "        compt_batch = 0\n",
        "\n",
        "        all_batches = creer_batch_train_random(X_train,y_train)\n",
        "\n",
        "\n",
        "\n",
        "        num_batches = len(all_batches)\n",
        "        all_batches_indices = list(range(num_batches))\n",
        "\n",
        "        np.random.shuffle(all_batches_indices)\n",
        "\n",
        "        for batch_index in all_batches_indices:\n",
        "\n",
        "            compt_batch +=1\n",
        "            print(f'on en est au batch {compt_batch} sur {len(all_batches)}')\n",
        "\n",
        "\n",
        "        # Obtenir le batch correspondant à l'index mélangé\n",
        "            batch_data = all_batches[batch_index]\n",
        "\n",
        "            inputs = []\n",
        "            labels = []\n",
        "\n",
        "            for donnee,label in batch_data:\n",
        "                inputs.append(donnee)\n",
        "                labels.append(label)\n",
        "\n",
        "            # print(inputs)\n",
        "            # print(labels)\n",
        "\n",
        "            labels = torch.tensor(labels,dtype=torch.long).to(device)\n",
        "\n",
        "            bs = labels.size(0)\n",
        "\n",
        "            # réinitialiser les gradients stockés pour les paramètres du réseau neuronal\n",
        "            model.zero_grad()\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            # print(outputs.device)\n",
        "\n",
        "            # calculer la perte sur le training set\n",
        "            loss = loss_fn(outputs, labels)\n",
        "\n",
        "            # la back propagation\n",
        "            loss.backward()\n",
        "\n",
        "            # la descente de gradient (selon la methode Adam ici)\n",
        "            optimizer.step()\n",
        "\n",
        "            # stocker la loss et calculer le nombre de prédictions correctes\n",
        "            running_loss += loss\n",
        "            preds = (outputs >= 0.5).type(torch.float32)\n",
        "            preds_argmax = torch.argmax(preds, dim=1)\n",
        "            running_corrects += torch.sum(preds_argmax == labels)\n",
        "\n",
        "            # compter le nombre d'échantillons\n",
        "            size += bs\n",
        "\n",
        "            # print(loss/bs)\n",
        "\n",
        "        epoch_loss = running_loss.item() / size\n",
        "        epoch_acc = running_corrects.item() / size\n",
        "\n",
        "        loss_train[epoch_num] = epoch_loss\n",
        "        acc_train[epoch_num] = epoch_acc\n",
        "\n",
        "        print('Epoch {} - Loss: {:.4f} Acc: {:.4f}'.format(epoch_num+1, epoch_loss, epoch_acc))\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    print(loss_train,acc_train)\n",
        "\n",
        "    return loss_train, acc_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IO5KKATQ3_GT"
      },
      "source": [
        "# Le premier modèle :"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0E7Hu-23_GU"
      },
      "source": [
        "Ce premier réseau de neurones est basé sur l'article scientifique suivant :\n",
        "Detection of emotion by text analysis using machine learning ; Kristína Machová, Martina Szabóova , Ján Paralič and\n",
        "Ján Mičko (1 Department of Cybernetics and Artificial Intelligence, Faculty of Electrical Engineering and Informatics, Technical University of Košice, Košice, Slovakia, 2 Department of Social Sciences, Technical University of Košice, Košice, Slovakia)\n",
        "\n",
        "Les chercheurs y détaillent une architecture ayant en théorie 91% d'accurancy. Cette dernière est composé d'une couche d'embedding, une couche récurrente (LSTM), une couche de convolution, une récurrente et une couche de convolution avec des couches de dropout intermédiare.\n",
        "\n",
        "J'ai ici choisit de prendre la couche d'embedding proposé par le modèle BERT de google car les couches d'embedding sont compliquées à entrainer (pour extraire la sémantique, rajouter les tokens etc.)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WQxENLSx3_GU"
      },
      "outputs": [],
      "source": [
        "class analyser_emo(nn.Module):\n",
        "\n",
        "    def __init__(self, bert_model_name='bert-base-uncased', embedding_dim=128, p=0.5, max_input_length=50, num_classes=6, device = device):\n",
        "\n",
        "        super(analyser_emo, self).__init__()\n",
        "\n",
        "        self.max_length = max_input_length\n",
        "\n",
        "        #couche d'embeding BERT\n",
        "\n",
        "        # Charger le modèle BERT pré-entraîné et le tokenizer\n",
        "        self.bert = BertModel.from_pretrained(bert_model_name).to(device)\n",
        "        self.tokenizer = BertTokenizer.from_pretrained(bert_model_name)\n",
        "        # Définir la couche linéaire pour ajuster la dimension de l'embedding\n",
        "        self.linear_bert = nn.Linear(self.bert.config.hidden_size, embedding_dim).to(device)\n",
        "\n",
        "        # couche de dropout\n",
        "        self.dropout = nn.Dropout(p=p).to(device)\n",
        "\n",
        "        #couche recurrent 1\n",
        "        self.lstm_1 = nn.LSTM(input_size=embedding_dim, hidden_size=128, dropout=p, batch_first=True).to(device)\n",
        "\n",
        "        #couche conv 1\n",
        "        self.convolution_1 = nn.Conv1d(in_channels=128, out_channels=128, kernel_size=10, stride=3, padding=5).to(device)\n",
        "\n",
        "        #activation ReLU\n",
        "        self.activation_Relu = nn.ReLU().to(device)\n",
        "\n",
        "        #couche recurrent 2\n",
        "        self.lstm_2 = nn.LSTM(input_size=128, hidden_size=128, dropout=p, batch_first=True).to(device)\n",
        "\n",
        "        #couche conv 2\n",
        "        self.convolution_2 = nn.Conv1d(in_channels=128, out_channels=128, kernel_size=10, stride=3, padding=5).to(device)\n",
        "\n",
        "        #couche dense final\n",
        "        self.lin = nn.Linear(in_features=128*1, out_features=num_classes).to(device)\n",
        "\n",
        "        self.device = device\n",
        "\n",
        "\n",
        "    def forward(self, input_text):\n",
        "        inputs = self.tokenizer(input_text, return_tensors='pt', padding=True, truncation=True, max_length=self.max_length)\n",
        "\n",
        "        # Transférez les données d'entrée au bon dispositif\n",
        "        inputs = {name: tensor.to(self.device) for name, tensor in inputs.items()}\n",
        "        outputs = self.bert(**inputs)\n",
        "        # Obtenir l'embedding BERT et le redimensionner\n",
        "        bert_embedding = outputs.last_hidden_state.mean(dim=1)  # Moyenne des embeddings de chaque token\n",
        "        bert_embedding = self.linear_bert(bert_embedding)\n",
        "\n",
        "\n",
        "        dropout_1 = self.dropout(bert_embedding)\n",
        "        couche_rec_1, _ = self.lstm_1(dropout_1.unsqueeze(1))  # Ajouter une dimension pour la convolution 1D\n",
        "        couche_rec_1 = couche_rec_1.permute(0, 2, 1)\n",
        "        couche_conv_1 = self.convolution_1(couche_rec_1)  # Transposer les dimensions pour correspondre aux attentes de la couche de convolution\n",
        "        couche_act_relu = self.activation_Relu(couche_conv_1.permute(0, 2, 1))  # Transposer les dimensions pour correspondre aux attentes de la LSTM 2\n",
        "        couche_rec_2, _ = self.lstm_2(couche_act_relu)  # LSTM 2\n",
        "        couche_conv_2 = self.convolution_2(couche_rec_2.permute(0, 2, 1))  # Transposer les dimensions pour correspondre aux attentes de la couche de convolution\n",
        "        couche_lin = self.lin(couche_conv_2.squeeze())\n",
        "\n",
        "        output_final = torch.softmax(couche_lin, dim=-1)\n",
        "\n",
        "        return output_final.to(self.device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTHSZx9-3_GU"
      },
      "source": [
        "On test ici notre modèle pour voir si toutes les couches ont été bien reliés au niveau des dimensions.\n",
        "On peut voir que la sortie (la proba pour chaque classes) est bien repartie (un peu près une proba de 1/6 ~ 0.167)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XmHanJT73_GU"
      },
      "outputs": [],
      "source": [
        "# 1er modèle test\n",
        "analyser_1 = analyser_emo()\n",
        "print(analyser_1.forward(['salut']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bK8gRxkP3_GU"
      },
      "source": [
        "importation et entrainement du premier modèle :\n",
        "\n",
        "---\n",
        "\n",
        "On va ici importer et mettre notre modèle sur cuda pour pouvoir entrainer notre modèle (sur CPU, la RAM crash assez vite)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "upEPMIQy3_GV"
      },
      "outputs": [],
      "source": [
        "analyser_emotion = analyser_emo()\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    # Parcourir les paramètres de votre modèle\n",
        "    for param in analyser_emotion.parameters():\n",
        "        # Transférer chaque paramètre sur CUDA\n",
        "        param.data = param.data.to('cuda')\n",
        "\n",
        "    # Transférer également votre modèle sur CUDA\n",
        "    analyser_emotion.to('cuda')\n",
        "else:\n",
        "    print(\"CUDA n'est pas disponible. Les tenseurs resteront sur CPU.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4Hc0hwQ3_GV"
      },
      "source": [
        "---\n",
        "\n",
        "Ici on va \"geler\" les poids de la couche d'embedding pour améliorer la vitesse de l'entrainement. En effet cette couche étant déjà pré-entraînée, elle sort des tokens déjà utiles pour notre réseau, pas besoin de la ré-entrainer (d'autant que cela demande beaucoup de puissance de calcul et de temps).\n",
        "Pour geler une couche, on arrête de traquer le gradient."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lEB5s6913_GV"
      },
      "outputs": [],
      "source": [
        "# gel des poids de la couche de l'embedding\n",
        "\n",
        "for name, param in analyser_emotion.named_parameters():\n",
        "    if 'bert' in name or 'tokenizer' in name or 'linear_bert' in name:\n",
        "        param.requires_grad = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTNt0SMB3_GV"
      },
      "source": [
        "\n",
        "---\n",
        "On commence alors l'entrainement en utilisant la méthode Adam (l'adaptation du gradient en fonction de ses moments d'ordre 1 et 2 actuel et précédent est utile ici) et la cross entropy comme fonction de perte (car on a des classes).\n",
        "\n",
        "Le learning rate est à modifier arbitrairement mais cependant, le modèle ayant du mal à s'entrainer (comme vous le verrez), j'ai choisi ici un learning rate élevé.\n",
        "(remarque : un lr de 100 donne une loss qui diverge parfois et est donc trop élevé)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s_SeQ65x3_GV"
      },
      "outputs": [],
      "source": [
        "learning_rate = 10\n",
        "n_epochs = 5\n",
        "\n",
        "optimizer = optim.Adam(analyser_emotion.parameters(), lr=learning_rate)\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "odWFbPlu3_GV",
        "outputId": "ca250ee5-8650-4c5f-dd35-d7c5c513af71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "on en est au batch 1 sur 47\n",
            "on en est au batch 2 sur 47\n",
            "on en est au batch 3 sur 47\n",
            "on en est au batch 4 sur 47\n",
            "on en est au batch 5 sur 47\n",
            "on en est au batch 6 sur 47\n",
            "on en est au batch 7 sur 47\n",
            "on en est au batch 8 sur 47\n",
            "on en est au batch 9 sur 47\n",
            "on en est au batch 10 sur 47\n",
            "on en est au batch 11 sur 47\n",
            "on en est au batch 12 sur 47\n",
            "on en est au batch 13 sur 47\n",
            "on en est au batch 14 sur 47\n",
            "on en est au batch 15 sur 47\n",
            "on en est au batch 16 sur 47\n",
            "on en est au batch 17 sur 47\n",
            "on en est au batch 18 sur 47\n",
            "on en est au batch 19 sur 47\n",
            "on en est au batch 20 sur 47\n",
            "on en est au batch 21 sur 47\n",
            "on en est au batch 22 sur 47\n",
            "on en est au batch 23 sur 47\n",
            "on en est au batch 24 sur 47\n",
            "on en est au batch 25 sur 47\n",
            "on en est au batch 26 sur 47\n",
            "on en est au batch 27 sur 47\n",
            "on en est au batch 28 sur 47\n",
            "on en est au batch 29 sur 47\n",
            "on en est au batch 30 sur 47\n",
            "on en est au batch 31 sur 47\n",
            "on en est au batch 32 sur 47\n",
            "on en est au batch 33 sur 47\n",
            "on en est au batch 34 sur 47\n",
            "on en est au batch 35 sur 47\n",
            "on en est au batch 36 sur 47\n",
            "on en est au batch 37 sur 47\n",
            "on en est au batch 38 sur 47\n",
            "on en est au batch 39 sur 47\n",
            "on en est au batch 40 sur 47\n",
            "on en est au batch 41 sur 47\n",
            "on en est au batch 42 sur 47\n",
            "on en est au batch 43 sur 47\n",
            "on en est au batch 44 sur 47\n",
            "on en est au batch 45 sur 47\n",
            "on en est au batch 46 sur 47\n",
            "on en est au batch 47 sur 47\n",
            "Epoch 1 - Loss: 0.0299 Acc: 0.1667\n",
            "on en est au batch 1 sur 47\n",
            "on en est au batch 2 sur 47\n",
            "on en est au batch 3 sur 47\n",
            "on en est au batch 4 sur 47\n",
            "on en est au batch 5 sur 47\n",
            "on en est au batch 6 sur 47\n",
            "on en est au batch 7 sur 47\n",
            "on en est au batch 8 sur 47\n",
            "on en est au batch 9 sur 47\n",
            "on en est au batch 10 sur 47\n",
            "on en est au batch 11 sur 47\n",
            "on en est au batch 12 sur 47\n",
            "on en est au batch 13 sur 47\n",
            "on en est au batch 14 sur 47\n",
            "on en est au batch 15 sur 47\n",
            "on en est au batch 16 sur 47\n",
            "on en est au batch 17 sur 47\n",
            "on en est au batch 18 sur 47\n",
            "on en est au batch 19 sur 47\n",
            "on en est au batch 20 sur 47\n",
            "on en est au batch 21 sur 47\n",
            "on en est au batch 22 sur 47\n",
            "on en est au batch 23 sur 47\n",
            "on en est au batch 24 sur 47\n",
            "on en est au batch 25 sur 47\n",
            "on en est au batch 26 sur 47\n",
            "on en est au batch 27 sur 47\n",
            "on en est au batch 28 sur 47\n",
            "on en est au batch 29 sur 47\n",
            "on en est au batch 30 sur 47\n",
            "on en est au batch 31 sur 47\n",
            "on en est au batch 32 sur 47\n",
            "on en est au batch 33 sur 47\n",
            "on en est au batch 34 sur 47\n",
            "on en est au batch 35 sur 47\n",
            "on en est au batch 36 sur 47\n",
            "on en est au batch 37 sur 47\n",
            "on en est au batch 38 sur 47\n",
            "on en est au batch 39 sur 47\n",
            "on en est au batch 40 sur 47\n",
            "on en est au batch 41 sur 47\n",
            "on en est au batch 42 sur 47\n",
            "on en est au batch 43 sur 47\n",
            "on en est au batch 44 sur 47\n",
            "on en est au batch 45 sur 47\n",
            "on en est au batch 46 sur 47\n",
            "on en est au batch 47 sur 47\n",
            "Epoch 2 - Loss: 0.0299 Acc: 0.1667\n",
            "on en est au batch 1 sur 47\n",
            "on en est au batch 2 sur 47\n",
            "on en est au batch 3 sur 47\n",
            "on en est au batch 4 sur 47\n",
            "on en est au batch 5 sur 47\n",
            "on en est au batch 6 sur 47\n",
            "on en est au batch 7 sur 47\n",
            "on en est au batch 8 sur 47\n",
            "on en est au batch 9 sur 47\n",
            "on en est au batch 10 sur 47\n",
            "on en est au batch 11 sur 47\n",
            "on en est au batch 12 sur 47\n",
            "on en est au batch 13 sur 47\n",
            "on en est au batch 14 sur 47\n",
            "on en est au batch 15 sur 47\n",
            "on en est au batch 16 sur 47\n",
            "on en est au batch 17 sur 47\n",
            "on en est au batch 18 sur 47\n",
            "on en est au batch 19 sur 47\n",
            "on en est au batch 20 sur 47\n",
            "on en est au batch 21 sur 47\n",
            "on en est au batch 22 sur 47\n",
            "on en est au batch 23 sur 47\n",
            "on en est au batch 24 sur 47\n",
            "on en est au batch 25 sur 47\n",
            "on en est au batch 26 sur 47\n",
            "on en est au batch 27 sur 47\n",
            "on en est au batch 28 sur 47\n",
            "on en est au batch 29 sur 47\n",
            "on en est au batch 30 sur 47\n",
            "on en est au batch 31 sur 47\n",
            "on en est au batch 32 sur 47\n",
            "on en est au batch 33 sur 47\n",
            "on en est au batch 34 sur 47\n",
            "on en est au batch 35 sur 47\n",
            "on en est au batch 36 sur 47\n",
            "on en est au batch 37 sur 47\n",
            "on en est au batch 38 sur 47\n",
            "on en est au batch 39 sur 47\n",
            "on en est au batch 40 sur 47\n",
            "on en est au batch 41 sur 47\n",
            "on en est au batch 42 sur 47\n",
            "on en est au batch 43 sur 47\n",
            "on en est au batch 44 sur 47\n",
            "on en est au batch 45 sur 47\n",
            "on en est au batch 46 sur 47\n",
            "on en est au batch 47 sur 47\n",
            "Epoch 3 - Loss: 0.0299 Acc: 0.1667\n",
            "on en est au batch 1 sur 47\n",
            "on en est au batch 2 sur 47\n",
            "on en est au batch 3 sur 47\n",
            "on en est au batch 4 sur 47\n",
            "on en est au batch 5 sur 47\n",
            "on en est au batch 6 sur 47\n",
            "on en est au batch 7 sur 47\n",
            "on en est au batch 8 sur 47\n",
            "on en est au batch 9 sur 47\n",
            "on en est au batch 10 sur 47\n",
            "on en est au batch 11 sur 47\n",
            "on en est au batch 12 sur 47\n",
            "on en est au batch 13 sur 47\n",
            "on en est au batch 14 sur 47\n",
            "on en est au batch 15 sur 47\n",
            "on en est au batch 16 sur 47\n",
            "on en est au batch 17 sur 47\n",
            "on en est au batch 18 sur 47\n",
            "on en est au batch 19 sur 47\n",
            "on en est au batch 20 sur 47\n",
            "on en est au batch 21 sur 47\n",
            "on en est au batch 22 sur 47\n",
            "on en est au batch 23 sur 47\n",
            "on en est au batch 24 sur 47\n",
            "on en est au batch 25 sur 47\n",
            "on en est au batch 26 sur 47\n",
            "on en est au batch 27 sur 47\n",
            "on en est au batch 28 sur 47\n",
            "on en est au batch 29 sur 47\n",
            "on en est au batch 30 sur 47\n",
            "on en est au batch 31 sur 47\n",
            "on en est au batch 32 sur 47\n",
            "on en est au batch 33 sur 47\n",
            "on en est au batch 34 sur 47\n",
            "on en est au batch 35 sur 47\n",
            "on en est au batch 36 sur 47\n",
            "on en est au batch 37 sur 47\n",
            "on en est au batch 38 sur 47\n",
            "on en est au batch 39 sur 47\n",
            "on en est au batch 40 sur 47\n",
            "on en est au batch 41 sur 47\n",
            "on en est au batch 42 sur 47\n",
            "on en est au batch 43 sur 47\n",
            "on en est au batch 44 sur 47\n",
            "on en est au batch 45 sur 47\n",
            "on en est au batch 46 sur 47\n",
            "on en est au batch 47 sur 47\n",
            "Epoch 4 - Loss: 0.0299 Acc: 0.1667\n",
            "on en est au batch 1 sur 47\n",
            "on en est au batch 2 sur 47\n",
            "on en est au batch 3 sur 47\n",
            "on en est au batch 4 sur 47\n",
            "on en est au batch 5 sur 47\n",
            "on en est au batch 6 sur 47\n",
            "on en est au batch 7 sur 47\n",
            "on en est au batch 8 sur 47\n",
            "on en est au batch 9 sur 47\n",
            "on en est au batch 10 sur 47\n",
            "on en est au batch 11 sur 47\n",
            "on en est au batch 12 sur 47\n",
            "on en est au batch 13 sur 47\n",
            "on en est au batch 14 sur 47\n",
            "on en est au batch 15 sur 47\n",
            "on en est au batch 16 sur 47\n",
            "on en est au batch 17 sur 47\n",
            "on en est au batch 18 sur 47\n",
            "on en est au batch 19 sur 47\n",
            "on en est au batch 20 sur 47\n",
            "on en est au batch 21 sur 47\n",
            "on en est au batch 22 sur 47\n",
            "on en est au batch 23 sur 47\n",
            "on en est au batch 24 sur 47\n",
            "on en est au batch 25 sur 47\n",
            "on en est au batch 26 sur 47\n",
            "on en est au batch 27 sur 47\n",
            "on en est au batch 28 sur 47\n",
            "on en est au batch 29 sur 47\n",
            "on en est au batch 30 sur 47\n",
            "on en est au batch 31 sur 47\n",
            "on en est au batch 32 sur 47\n",
            "on en est au batch 33 sur 47\n",
            "on en est au batch 34 sur 47\n",
            "on en est au batch 35 sur 47\n",
            "on en est au batch 36 sur 47\n",
            "on en est au batch 37 sur 47\n",
            "on en est au batch 38 sur 47\n",
            "on en est au batch 39 sur 47\n",
            "on en est au batch 40 sur 47\n",
            "on en est au batch 41 sur 47\n",
            "on en est au batch 42 sur 47\n",
            "on en est au batch 43 sur 47\n",
            "on en est au batch 44 sur 47\n",
            "on en est au batch 45 sur 47\n",
            "on en est au batch 46 sur 47\n",
            "on en est au batch 47 sur 47\n",
            "Epoch 5 - Loss: 0.0299 Acc: 0.1667\n",
            "[0.02986315 0.02986293 0.02986282 0.02986274 0.02986271] [0.16666667 0.16666667 0.16666667 0.16666667 0.16666667]\n"
          ]
        }
      ],
      "source": [
        "torch.cuda.empty_cache()  # Videz le cache CUDA\n",
        "\n",
        "print(n_epochs, learning_rate)\n",
        "\n",
        "training_loss , training_acc = train(analyser_emotion,  loss_fn, optimizer, n_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dge1niLc3_GV",
        "outputId": "d1a33e67-3614-4a01-cef1-f08094c9c20e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'CE loss')"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(training_loss)\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('CE loss')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JKrsUcKU3_GW"
      },
      "outputs": [],
      "source": [
        "plt.plot(training_acc)\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('acc')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqUMBRDE3_GW"
      },
      "source": [
        "\n",
        "---\n",
        "En conclusion de ce modèle : il est sans doute efficace selon l'article mais beaucoup trop compliqué à entrainer avec nos ressources. Cela est sans doute dû au LSTM qui possède énormément de paramètres ( ici 4*(128+128+1)*128=131 584 par couche récurrente, donc avec les couches de convolution ça fait beaucoup)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wh-ORlV3_GW"
      },
      "source": [
        "# 2ème modèle (en utilisant le transformer BERT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtWngzQJ3_GW"
      },
      "source": [
        "BERT :  Bidirectional Encoder Representations from Transformers\n",
        "\n",
        "Les transformers sont très efficace pour le NLP, c'est pourquoi j'ai choisit un transformers pré-entrainé pour résoudre notre problème. Le transformer BERT, au vu de sa description et des bases de données sur lesquelles il s'est entrainé semblait alors être le plus pertinent (même si le choix est quelque peu arbitraire).\n",
        "\n",
        "BERT a été pré-entraîné (par Google AI) sur un large corpus de données textuelles provenant de diverses sources, telles que des articles de Wikipédia, des livres, des documents web, des forums en ligne, des articles de presse, etc. L'objectif de ce pré-entraînement était de capturer des représentations linguistiques générales qui peuvent être ensuite adaptées à différentes tâches spécifiques.\n",
        "\n",
        "J'utiliserai ici la tâche de classification. On peut voir que BERT n'a pas été entrainé sur la base de donnée IEMOCAP car l'accuracy est au départ de 0.167\n",
        "\n",
        "On définit donc une classe pour notre modèle basé sur BERT :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rBc2qERk3_GW"
      },
      "outputs": [],
      "source": [
        "class BertClassifier(nn.Module):\n",
        "    def __init__(self, num_classes=6, pretrained_model_name='bert-base-uncased', device = device):\n",
        "        super(BertClassifier, self).__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.tokenizer = BertTokenizer.from_pretrained(pretrained_model_name)\n",
        "        self.bert = BertForSequenceClassification.from_pretrained(pretrained_model_name, num_labels=num_classes).to(device)\n",
        "\n",
        "        self.device = device\n",
        "\n",
        "\n",
        "    def forward(self, input_text):\n",
        "        # Tokenization\n",
        "        inputs = self.tokenizer(input_text, return_tensors='pt', padding=True, truncation=True).to(self.device)\n",
        "        # Classification\n",
        "        outputs = self.bert(**inputs)\n",
        "        outputs_final = torch.softmax(outputs.logits, dim=-1)\n",
        "\n",
        "        return outputs_final"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5nGg6P73_GX"
      },
      "source": [
        "---\n",
        "importation du modèle et entrainement du second model (de la même manière que pour le premier modèle)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8S9Vrfmd3_GX"
      },
      "outputs": [],
      "source": [
        "classificateur_emo_bert = BertClassifier()\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(\"on va sur cuda\")\n",
        "    # Parcourir les paramètres de votre modèle\n",
        "    for param in classificateur_emo_bert.parameters():\n",
        "        # Transférer chaque paramètre sur CUDA\n",
        "        param.data = param.data.to('cuda')\n",
        "\n",
        "    # Transférer également votre modèle sur CUDA\n",
        "    classificateur_emo_bert.to('cuda')\n",
        "else:\n",
        "    print(\"CUDA n'est pas disponible. Les tenseurs resteront sur CPU.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzCDQJL03_GX"
      },
      "source": [
        "---\n",
        "Ici, le lr est choisit beaucoup plus petit car ce modèle converge beaucoup plus rapidement que le premier. En général, je choisis un lr de 1e-1 pour les 10 premières epochs, puis un 1e-2 pour les 10 suivantes et enfin un 1e-3 pour le reste. Cela permet que le modèle reste précis mais s'entraine rapidement."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n_inpRBX3_Gc"
      },
      "outputs": [],
      "source": [
        "learning_rate = 1e-3\n",
        "n_epochs = 10\n",
        "\n",
        "optimizer = optim.Adam(classificateur_emo_bert.parameters(), lr=learning_rate)\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Q1DLE0y3_Gc"
      },
      "source": [
        "(j'ai gardé les différentes loss et accuracy lors des entrainements précédents. On peut notamment voir que le modèle arrive à 82% d'accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2tdh6N7f3_Gc"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()  # Videz le cache CUDA\n",
        "\n",
        "print(n_epochs,learning_rate)\n",
        "training_loss , training_acc = train(classificateur_emo_bert, loss_fn, optimizer, n_epochs)\n",
        "\n",
        "plt.plot(training_loss)\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('CE loss')\n",
        "\n",
        "plt.plot(training_acc)\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('acc')\n",
        "\n",
        "# loss =[0.02765068 0.02725666 0.02704823 0.02664275 0.02634453 0.02612578\n",
        "#  0.02590721 0.0254673  0.02523997 0.02495639 0.02461087 0.02422475\n",
        "#  0.02403708 0.02364573 0.02349734 0.0232953  0.02313531 0.02286776\n",
        "#  0.02290078 0.02264368 0.0223601  0.02226738 0.0221536  0.02195324\n",
        "#  0.02183018 0.02187026 0.02168758 0.02147265 0.02150043 0.02145139]\n",
        "# acc =[0.35531915 0.39397163 0.40957447 0.43617021 0.4606383  0.46241135\n",
        "#  0.48262411 0.52092199 0.53758865 0.55957447 0.5893617  0.60460993\n",
        "#  0.61843972 0.63971631 0.64751773 0.66631206 0.66595745 0.68439716\n",
        "#  0.68439716 0.69822695 0.71702128 0.71950355 0.72304965 0.7393617\n",
        "#  0.74007092 0.73723404 0.75248227 0.76879433 0.76347518 0.76312057]\n",
        "# loss =[0.02145962 0.02129947 0.02131816 0.02125578 0.02118106 0.02104496\n",
        "#  0.02109007 0.02104837 0.02093198 0.02097597 0.02086502 0.02083805\n",
        "#  0.02093464 0.02080769 0.02071834 0.0206867  0.02066573 0.02071064\n",
        "#  0.02064641 0.02066663 0.02059581 0.02064744 0.02055597 0.0205692\n",
        "#  0.02048292 0.02056026 0.02053437 0.02048611 0.02040847 0.02040384]\n",
        "#  acc =[0.76205674 0.77021277 0.76843972 0.77411348 0.77836879 0.78865248\n",
        "#  0.78652482 0.78687943 0.79326241 0.78865248 0.79751773 0.7964539\n",
        "#  0.7929078  0.80141844 0.80602837 0.80815603 0.80567376 0.80390071\n",
        "#  0.80992908 0.8070922  0.81028369 0.80886525 0.81347518 0.81028369\n",
        "#  0.81843972 0.81347518 0.8141844  0.81737589 0.82234043 0.8212766 ]\n",
        "\n",
        "# deuxième session en recommençant de zéro car le réseau s'est mal enregistré\n",
        "\n",
        "# loss =[0.01419637 0.01396663 0.013868   0.01357411 0.01312468 0.01280451\n",
        "#  0.01259687 0.01232456 0.01220601 0.01204682]\n",
        "#  acc =[0.16666667 0.18903319 0.22727273 0.28102453 0.36075036 0.41594517\n",
        "#  0.4498557  0.48268398 0.50180375 0.51623377]\n",
        "# loss =[0.01163287 0.0115118  0.01135006 0.01138314 0.01137112 0.01134926\n",
        "#  0.01140202 0.01118329 0.01117278 0.01125082]\n",
        "#  acc =[0.57395382 0.59632035 0.62121212 0.61147186 0.61616162 0.61796537\n",
        "#  0.60822511 0.64105339 0.64646465 0.62806638]\n",
        "# loss =[0.01116812 0.0110818  0.01125656 0.01110577 0.01117366 0.01113716\n",
        "#  0.01114397 0.01113306 0.01099516 0.01112097]\n",
        "#  acc =[0.64321789 0.65836941 0.63095238 0.65151515 0.64574315 0.65007215\n",
        "#  0.6453824  0.6468254  0.66594517 0.65367965]\n",
        "# loss =[0.01110605 0.01103843 0.01098787 0.01103318 0.01111039 0.01099524\n",
        "#  0.01115685 0.01109176 0.01114987 0.01110056]\n",
        "#  acc =[0.65151515 0.66017316 0.66991342 0.65873016 0.64862915 0.66738817\n",
        "#  0.64430014 0.6489899  0.6475469  0.6511544 ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twM6I0zE3_Gc"
      },
      "source": [
        "Conclusion sur ce modèle : ce dernier s'entraine bien plus rapidement que le modèle précédent et nous permet d'avoir des résultats bien plus quantitatif (proche de ceux de la litérrature scientifique)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JMXyR2E3_Gc"
      },
      "source": [
        "# 3eme modèle : utilisation de RoBERTa\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0iBizvDg3_Gd"
      },
      "source": [
        "Ici j'utilise RoBERTa (Robustly optimized BERT approach) qui est également un transformers. RoBERTa est une amélioration de BERT développée par Facebook AI. Il est conçu pour être plus robuste et performant que BERT en appliquant diverses techniques d'optimisation. RoBERTa est entraîné sur une quantité encore plus importante de données textuelles et utilise des stratégies d'entraînement plus avancées pour améliorer ses performances sur une variété de tâches de traitement du langage naturel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PkqXxNF93_Gd"
      },
      "outputs": [],
      "source": [
        "class RobertaClassifier(nn.Module):\n",
        "    def __init__(self, num_classes=6, pretrained_model_name='roberta-base', device=device):\n",
        "        super(RobertaClassifier, self).__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.tokenizer = RobertaTokenizer.from_pretrained(pretrained_model_name)\n",
        "        self.roberta = RobertaForSequenceClassification.from_pretrained(pretrained_model_name, num_labels=num_classes).to(device)\n",
        "        self.device = device\n",
        "\n",
        "    def forward(self, input_text):\n",
        "        # Tokenization\n",
        "        inputs = self.tokenizer(input_text, return_tensors='pt', padding=True, truncation=True).to(self.device)\n",
        "        # Classification\n",
        "        outputs = self.roberta(**inputs)\n",
        "        outputs_final = torch.softmax(outputs.logits, dim=-1)\n",
        "\n",
        "        return outputs_final"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkrEhkHJ3_Gd"
      },
      "source": [
        "---\n",
        "Importation et entrainement du troisième modèle :\n",
        "\n",
        "(de même que précédement)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QwpTwZcS3_Gd"
      },
      "outputs": [],
      "source": [
        "classificateur_emo_RoBERTa = RobertaClassifier()\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(\"on va sur cuda\")\n",
        "    # Parcourir les paramètres de votre modèle\n",
        "    for param in classificateur_emo_RoBERTa.parameters():\n",
        "        # Transférer chaque paramètre sur CUDA\n",
        "        param.data = param.data.to('cuda')\n",
        "\n",
        "    # Transférer également votre modèle sur CUDA\n",
        "    classificateur_emo_RoBERTa.to('cuda')\n",
        "else:\n",
        "    print(\"CUDA n'est pas disponible. Les tenseurs resteront sur CPU.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMT-RDdw3_Gd"
      },
      "source": [
        "(j'applique ici la même méthode de variation du learning rate que pour BERT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MbJfuYpj3_Gd"
      },
      "outputs": [],
      "source": [
        "learning_rate = 1e-2\n",
        "n_epochs = 10\n",
        "\n",
        "optimizer = optim.Adam(classificateur_emo_RoBERTa.parameters(), lr=learning_rate)\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LGjkZUV3_Ge"
      },
      "source": [
        "(J'ai également ici conservé les valeurs de la loss et de l'accuracy pour l'entraineemnt de ce modèle et on observe qu'on obtient une accuracy ~ 67%)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RA_qHtlO3_Ge"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()  # Videz le cache CUDA\n",
        "print(learning_rate, n_epochs)\n",
        "training_loss , training_acc = train(classificateur_emo_RoBERTa, loss_fn, optimizer, n_epochs)\n",
        "\n",
        "plt.plot(training_loss)\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('CE loss')\n",
        "\n",
        "plt.plot(training_acc)\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('acc')\n",
        "\n",
        "\n",
        "# loss =[0.02987032 0.02985641 0.02983716 0.02940839 0.02915803 0.02891392\n",
        "#  0.02824112 0.0284073  0.02801978 0.02795586]\n",
        "#  acc =[0.16666667 0.16666667 0.16666667 0.18085106 0.22588652 0.2606383\n",
        "#  0.3248227  0.31205674 0.34078014 0.3393617 ]\n",
        "# loss =[0.02692681 0.02615466 0.02586578 0.0257286  0.02542788 0.02515948\n",
        "#  0.02547382 0.02507261 0.02493977 0.02456494 0.02456875 0.02448062\n",
        "#  0.02458525 0.02442469 0.02412935 0.02420645 0.02396414 0.02406923\n",
        "#  0.02386605 0.02396385]\n",
        "#  acc =[0.42056738 0.4712766  0.48723404 0.49219858 0.51312057 0.53546099\n",
        "#  0.51489362 0.5358156  0.5429078  0.56631206 0.56950355 0.5751773\n",
        "#  0.5677305  0.57801418 0.59609929 0.58900709 0.60531915 0.59539007\n",
        "#  0.61170213 0.60390071]\n",
        "# on double la taille du batch :\n",
        "# loss =[0.01170279 0.01180711 0.01186781 0.0116768  0.01178388 0.01169416\n",
        "#  0.01167699 0.0116847  0.01166893 0.01164661 0.01165959 0.01160242\n",
        "#  0.01163244 0.01144577 0.01157438 0.01163777 0.01150932 0.01149496\n",
        "#  0.01153449 0.01158204]\n",
        "#  acc =[0.64202899 0.62862319 0.61992754 0.64275362 0.62971014 0.63876812\n",
        "#  0.64130435 0.64166667 0.64456522 0.64565217 0.64456522 0.65217391\n",
        "#  0.65       0.66992754 0.65543478 0.64673913 0.66304348 0.66268116\n",
        "# #  0.65724638 0.65543478]\n",
        "# loss =[0.01151284 0.01135067 0.011437   0.01143575 0.01153868 0.01159436\n",
        "#  0.01155198 0.0115619  0.01155206 0.01157762]\n",
        "#  acc =[0.66123188 0.68224638 0.67028986 0.66992754 0.66086957 0.65326087\n",
        "#  0.65652174 0.65471014 0.65615942 0.65507246]\n",
        "# loss =[0.01149768 0.01143562 0.01148595 0.01143775 0.01145755 0.01133253\n",
        "#  0.01157295 0.01138732 0.01149544 0.01141403]\n",
        "#  acc =[0.66485507 0.6692029  0.66630435 0.66775362 0.67210145 0.68297101\n",
        "#  0.65253623 0.67826087 0.6615942  0.67028986]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6I2ExE4_3_Ge"
      },
      "source": [
        "Conclusion sur ce modèle : nous n'observons pas une réel amélioration par rapport au modèle basé sur BERT."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7leGk_sn3_Ge"
      },
      "source": [
        "# Le test :"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcOZPFoT3_Ge"
      },
      "source": [
        "Ici j'ai fait un test manuel avec une phrase que l'on rentre pour voir réelement le résultat de notre travail."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "II9egaHP3_Ge"
      },
      "outputs": [],
      "source": [
        "#test manuel\n",
        "#rappel:\n",
        "    # 0: neutral,\n",
        "    # 1: angr\n",
        "    # 2: happy\n",
        "    # 3: sad\n",
        "    # 4: excited\n",
        "    # 5: frustrated\n",
        "\n",
        "sent = \"I can't wait to see you\"\n",
        "\n",
        "model = classificateur_emo_RoBERTa\n",
        "\n",
        "print(torch.argmax(model.forward([sent])))\n",
        "print(classificateur_emo_RoBERTa.forward([sent]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kScvkUUB3_Gf"
      },
      "source": [
        "Ici on va batcher les données de test en batch de 64 (pour que ça soit facilement traité par le GPU) et un batch avec ceux qui reste. Ici on ne fait plus attention de mélanger, le deséquilibre des classes dans le batch n'est plus un problème car le modèle ne s'entraine pas dessus."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vg_L6s-W3_Gf"
      },
      "outputs": [],
      "source": [
        "# pour batcher les données de test :\n",
        "print(len(X_test))\n",
        "\n",
        "X_test_batché = []\n",
        "\n",
        "for i in range(23):\n",
        "    batch_test = [X_test[j] for j in range(i*64,(i+1)*64)]\n",
        "    X_test_batché.append(batch_test)\n",
        "\n",
        "\n",
        "X_test_batché.append([X_test[1474],X_test[1475]])\n",
        "\n",
        "print(f\"nombre de batch de test {len(X_test_batché)}\")\n",
        "\n",
        "y_test_batché = []\n",
        "\n",
        "for i in range(23):\n",
        "    batch_test = [y_test[j] for j in range(i*64,(i+1)*64)]\n",
        "    y_test_batché.append(batch_test)\n",
        "\n",
        "y_test_batché.append([y_test[1474],y_test[1475]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AY88xz5r3_Gf"
      },
      "source": [
        "\n",
        "---\n",
        "\n",
        "Ici fonction de test classique, on fait bien attention à mettre la variable model.train sur False et a ne pas faire de back-prop ou de descente de gradient.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TmVewEgr3_Gf"
      },
      "outputs": [],
      "source": [
        "def test(model,donnee_test,label_test,metric):\n",
        "    model.train(False)\n",
        "    loss_tot = 0\n",
        "    running_corrects = 0.0 # nombre de prédiction correct\n",
        "    running_loss = 0.0 # loss\n",
        "\n",
        "\n",
        "    for i in range(len(donnee_test)):\n",
        "\n",
        "        input = donnee_test[i]\n",
        "        label = label_test[i]\n",
        "        model.zero_grad()\n",
        "        output = model(input)\n",
        "        label = torch.tensor(label).to(device)\n",
        "\n",
        "\n",
        "        loss = metric(output,label)\n",
        "\n",
        "        preds = (output >= 0.5).type(torch.float32)\n",
        "        preds_argmax = torch.argmax(preds, dim=1)\n",
        "        running_corrects += torch.sum(preds_argmax == label)\n",
        "\n",
        "        running_loss += loss\n",
        "\n",
        "    size = len(X_test)\n",
        "\n",
        "    loss_tot = running_loss / size\n",
        "    acc = running_corrects.item() / size\n",
        "\n",
        "\n",
        "    return loss_tot, acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUiHQMq33_Gf"
      },
      "source": [
        "---\n",
        "\n",
        "Ici j'ai également conservé certaines valeurs de loss et d'accuracy pour les modèles. On observe qu'on se situe plus vers 50% pour la phase de test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HNJGTer13_Gf"
      },
      "outputs": [],
      "source": [
        "\n",
        "torch.cuda.empty_cache()  # Videz le cache CUDA\n",
        "\n",
        "model_a_tester = classificateur_emo_RoBERTa\n",
        "\n",
        "with torch.no_grad():\n",
        "  loss_test, acc_test = test(model= model_a_tester, donnee_test=X_test_batché, label_test=y_test_batché, metric=loss_fn)\n",
        "\n",
        "print(loss_test, acc_test)\n",
        "\n",
        "# pour RoBERTa :\n",
        "\n",
        "# tensor(0.0247, device='cuda:0') 0.4993224932249323\n",
        "# tensor(0.0244, device='cuda:0') 0.5169376693766937\n",
        "# tensor(0.0244, device='cuda:0') 0.5223577235772358\n",
        "# tensor(0.0244, device='cuda:0') 0.521680216802168\n",
        "# tensor(0.0244, device='cuda:0') 0.521680216802168\n",
        "\n",
        "# pour BERT:\n",
        "# tensor(0.0255, device='cuda:0') 0.45121951219512196 au bout de 10 epochs\n",
        "# tensor(0.0243, device='cuda:0') 0.5277777777777778 au bout de 20 epochs\n",
        "# tensor(0.0243, device='cuda:0') 0.5230352303523035 au bout de 30 epochs\n",
        "# tensor(0.0243, device='cuda:0') 0.5271002710027101 au bout de 40 epochs\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}